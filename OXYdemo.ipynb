{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HIrhUAiaqDE4"
   },
   "outputs": [],
   "source": [
    "\n",
    "#!pip install ipywidgets\n",
    "#!pip install interpret\n",
    "#!pip install dice-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ap4BbjTHRXL8"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from interpret import show\n",
    "from interpret.blackbox import LimeTabular\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import display, clear_output\n",
    "# DiCE imports\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers  # helper functions\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HUL8Ow6hfyGM"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, auc\n",
    "def evalBinaryClassifier(model, x, y, labels=['Positives','Negatives']):\n",
    "    '''\n",
    "    Visualize the performance of  a Logistic Regression Binary Classifier.\n",
    "    \n",
    "    Displays a labelled Confusion Matrix, distributions of the predicted\n",
    "    probabilities for both classes, the ROC curve, and F1 score of a fitted\n",
    "    Binary Logistic Classifier. Author: gregcondit.com/articles/logr-charts\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : fitted scikit-learn model with predict_proba & predict methods\n",
    "        and classes_ attribute. Typically LogisticRegression or \n",
    "        LogisticRegressionCV\n",
    "    \n",
    "    x : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples\n",
    "        in the data to be tested, and n_features is the number of features\n",
    "    \n",
    "    y : array-like, shape (n_samples,)\n",
    "        Target vector relative to x.\n",
    "    \n",
    "    labels: list, optional\n",
    "        list of text labels for the two classes, with the positive label first\n",
    "        \n",
    "    Displays\n",
    "    ----------\n",
    "    3 Subplots\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    F1: float\n",
    "    '''\n",
    "    #model predicts probabilities of positive class\n",
    "    p = model.predict_proba(x)\n",
    "    if len(model.classes_)!=2:\n",
    "        raise ValueError('A binary class problem is required')\n",
    "    if model.classes_[1] == 1:\n",
    "        pos_p = p[:,1]\n",
    "    elif model.classes_[0] == 1:\n",
    "        pos_p = p[:,0]\n",
    "    \n",
    "    #FIGURE\n",
    "    plt.figure(figsize=[15,4])\n",
    "    \n",
    "    #1 -- Confusion matrix\n",
    "    cm = confusion_matrix(y,model.predict(x))\n",
    "    plt.subplot(131)\n",
    "    ax = sns.heatmap(cm, annot=True, cmap='Blues', cbar=False, \n",
    "                annot_kws={\"size\": 14}, fmt='g')\n",
    "    cmlabels = ['True Negatives', 'False Positives',\n",
    "              'False Negatives', 'True Positives']\n",
    "    for i,t in enumerate(ax.texts):\n",
    "        t.set_text(t.get_text() + \"\\n\" + cmlabels[i])\n",
    "    plt.title('Confusion Matrix', size=15)\n",
    "    plt.xlabel('Predicted Values', size=13)\n",
    "    plt.ylabel('True Values', size=13)\n",
    "      \n",
    "    #2 -- Distributions of Predicted Probabilities of both classes\n",
    "    df = pd.DataFrame({'probPos':pos_p, 'target': y})\n",
    "    plt.subplot(132)\n",
    "    plt.hist(df[df.target==1].probPos, density=True, bins=25,\n",
    "             alpha=.5, color='green',  label=labels[0])\n",
    "    plt.hist(df[df.target==0].probPos, density=True, bins=25,\n",
    "             alpha=.5, color='red', label=labels[1])\n",
    "    plt.axvline(.5, color='blue', linestyle='--', label='Boundary')\n",
    "    plt.xlim([0,1])\n",
    "    plt.title('Distributions of Predictions', size=15)\n",
    "    plt.xlabel('Positive Probability (predicted)', size=13)\n",
    "    plt.ylabel('Samples (normalized scale)', size=13)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    \n",
    "    #3 -- ROC curve with annotated decision point\n",
    "    fp_rates, tp_rates, _ = roc_curve(y,p[:,1])\n",
    "    roc_auc = auc(fp_rates, tp_rates)\n",
    "    plt.subplot(133)\n",
    "    plt.plot(fp_rates, tp_rates, color='green',\n",
    "             lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], lw=1, linestyle='--', color='grey')\n",
    "    #plot current decision point:\n",
    "    tn, fp, fn, tp = [i for i in cm.ravel()]\n",
    "    plt.plot(fp/(fp+tn), tp/(tp+fn), 'bo', markersize=8, label='Decision Point')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', size=13)\n",
    "    plt.ylabel('True Positive Rate', size=13)\n",
    "    plt.title('ROC Curve', size=15)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.subplots_adjust(wspace=.3)\n",
    "    plt.show()\n",
    "    #Print and Return the F1 score\n",
    "    tn, fp, fn, tp = [i for i in cm.ravel()]\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    F1 = 2*(precision * recall) / (precision + recall)\n",
    "    printout = (\n",
    "        f'Precision: {round(precision,2)} | '\n",
    "        f'Recall: {round(recall,2)} | '\n",
    "        f'F1 Score: {round(F1,2)} | '\n",
    "    )\n",
    "    print(printout)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4zDDadYkRugr"
   },
   "outputs": [],
   "source": [
    "# load and read data\n",
    "f = open('oxy_data.csv')\n",
    "df = pd.read_csv(f, header=0, index_col=False, engine='c', encoding='UTF-8')\n",
    "\n",
    "# delete Nan values from the feature dataframe\n",
    "df_column_list = df.columns.tolist()  # extract all column names into a list\n",
    "for column_name in df_column_list:\n",
    "    df = df.drop(df.index[df[column_name] == 'NA()'])\n",
    "\n",
    "# delete Nan values from the feature dataframe\n",
    "df_column_list = df.columns.tolist()  # extract all column names into a list\n",
    "for column_name in df_column_list:\n",
    "    df = df.drop(df.index[df[column_name] == '2P'])\n",
    "\n",
    "#drop all rows with null values\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "#rearranging coloumns to bring outcome to front\n",
    "df_column_list = df.columns.tolist() \n",
    "temp = df_column_list[0]\n",
    "df_column_list[0] = df_column_list[1];\n",
    "df_column_list[1] = temp\n",
    "df_column_list\n",
    "df=df.reindex(columns=df_column_list)\n",
    "df.head()\n",
    "\n",
    "#SPLIT SETS\n",
    "X, y = df[df.columns[1:34]], df[df.columns[0]] \n",
    "X.head()\n",
    "\n",
    "# set appropriate datatypes\n",
    "X, y = X.astype(float), y.astype(int)\n",
    "\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0P_pI2rlWkRw"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# fit a linear logistic regression model\n",
    "model = LogisticRegression(max_iter = 300).fit(X_train, y_train)\n",
    "\n",
    "# print accuracies on train and test sets\n",
    "#print('Mean train accuracy for logistic regression: {:0.4f}'.format(model.score(X_train, y_train)))\n",
    "#print('Mean test accuracy for logistic regression: {:0.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SKZNOeI5dJHs"
   },
   "outputs": [],
   "source": [
    "H = X_test.head(1).reset_index(drop = \"True\")\n",
    "Z = H.to_dict('records')[0] #singular value to dictionary for updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cuBtsrngirC8"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fit a RandomForestClassifier\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators=60).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# print accuracies on train and test sets\n",
    "#print('Mean train accuracy for RandomForestClassifier: {:0.4f}'.format(model2.score(X_train, y_train)))\n",
    "#print('Mean test accuracy for RandomForestClassifier: {:0.4f}'.format(model2.score(X_test, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "23tEfglJlkyM"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#fit a GaussianNB\n",
    "\n",
    "model3 = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# print accuracies on train and test sets\n",
    "#print('Mean train accuracy for GaussianNB: {:0.4f}'.format(model3.score(X_train, y_train)))\n",
    "#print('Mean test accuracy for GaussianNB: {:0.4f}'.format(model3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "f1yus5O8l14K"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "#fit a VotingClassifier\n",
    "\n",
    "model4 = VotingClassifier(\n",
    "    estimators=[(\"lr\", model), (\"rf\", model2), (\"gnb\", model3)],\n",
    "    voting=\"soft\",\n",
    "    weights=[1, 1, 5],\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "# print accuracies on train and test sets\n",
    "#print('Mean train accuracy for VotingClassifier: {:0.4f}'.format(model4.score(X_train, y_train)))\n",
    "#print('Mean test accuracy for VotingClassifier: {:0.4f}'.format(model4.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ml2ybUazfyYG"
   },
   "outputs": [],
   "source": [
    "#F1 = evalBinaryClassifier(model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nbOjg-9Zi28m"
   },
   "outputs": [],
   "source": [
    "#F2 = evalBinaryClassifier(model2,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Fr-xtqhkloHO"
   },
   "outputs": [],
   "source": [
    "#F3 = evalBinaryClassifier(model3,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "McM3kIKnsMtr"
   },
   "outputs": [],
   "source": [
    "#find max and min values\n",
    "\n",
    "df_column_list = X.columns.tolist() \n",
    "df_column_list[1]\n",
    "l = (len(df_column_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hONfttBjUMXW"
   },
   "outputs": [],
   "source": [
    "def pred_val (A):\n",
    "\n",
    "  #predict output for all classifiers\n",
    "  prediction = [c.predict(A) for c in (model, model2, model3, model4)]\n",
    "  #print(\"Sample input: \") \n",
    "  #display(A.head(1))\n",
    "  #get prediction for only first sample\n",
    "  result = [pr[0] for pr in prediction]\n",
    "\n",
    "\n",
    "  # predict class probabilities for all classifiers\n",
    "  probas = [c.predict_proba(A) for c in (model, model2, model3, model4)]\n",
    "\n",
    "  # get class probabilities for the first sample in the dataset\n",
    "  class0_1 = [pr[0, 0] for pr in probas]\n",
    "  class1_1 = [pr[0, 1] for pr in probas]\n",
    "\n",
    "  #printing values\n",
    "  #prediction:\n",
    "\n",
    "  #print(\"The predicted class by LogisticRegression is: \" + str(result[0]) + \" with positive class probability being \" +str(max(class0_1[0],class1_1[0])))\n",
    "  #print(\"The predicted class by GaussianNB is: \" + str(result[1]) + \" with positive class probability being \" +str(max(class0_1[1],class1_1[1])))\n",
    "  #print(\"The predicted class by RandomForestClassifier is: \" + str(result[2]) + \" with positive class probability being \" +str(max(class0_1[2],class1_1[2])))\n",
    "  #print(\"The predicted class by VotingClassifier is: \" + str(result[3]) + \" with positive class probability being \" +str(max(class0_1[3],class1_1[3])))\n",
    "  return [class0_1[0],class1_1[0],class0_1[1],class1_1[1],class0_1[2],class1_1[2],class0_1[3],class1_1[3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BkYyqvm5TSne"
   },
   "outputs": [],
   "source": [
    "def pred (A):\n",
    "\n",
    "  #predict output for all classifiers\n",
    "  prediction = [c.predict(X_test) for c in (model, model2, model3, model4)]\n",
    "  print(\"Sample input: \") \n",
    "  display(X_test.head(1))\n",
    "  #get prediction for only first sample\n",
    "  result = [pr[0] for pr in prediction]\n",
    "\n",
    "\n",
    "  # predict class probabilities for all classifiers\n",
    "  probas = [c.predict_proba(X_test) for c in (model, model2, model3, model4)]\n",
    "\n",
    "  # get class probabilities for the first sample in the dataset\n",
    "  class0_1 = [pr[0, 0] for pr in probas]\n",
    "  class1_1 = [pr[0, 1] for pr in probas]\n",
    "\n",
    "  #printing values\n",
    "  #prediction:\n",
    "\n",
    "  print(\"The predicted class by LogisticRegression is: \" + str(result[0]) + \" with positive class probability being \" +str(max(class0_1[0],class1_1[0])))\n",
    "  print(\"The predicted class by GaussianNB is: \" + str(result[1]) + \" with positive class probability being \" +str(max(class0_1[1],class1_1[1])))\n",
    "  print(\"The predicted class by RandomForestClassifier is: \" + str(result[2]) + \" with positive class probability being \" +str(max(class0_1[2],class1_1[2])))\n",
    "  print(\"The predicted class by VotingClassifier is: \" + str(result[3]) + \" with positive class probability being \" +str(max(class0_1[3],class1_1[3])))\n",
    "\n",
    "  # plotting\n",
    "\n",
    "  N = 4  # number of groups\n",
    "  ind = np.arange(N)  # group positions\n",
    "  width = 0.35  # bar width\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "\n",
    "  # bars for classifier 1-3\n",
    "\n",
    "  p1 = ax.bar(ind, np.hstack(([class0_1[:-1], [0]])), width, color=\"green\", edgecolor=\"k\")\n",
    "  p2 = ax.bar(\n",
    "      ind + width,\n",
    "      np.hstack(([class1_1[:-1], [0]])),\n",
    "      width,\n",
    "      color=\"lightgreen\",\n",
    "      edgecolor=\"k\",\n",
    "  )\n",
    "\n",
    "  # bars for VotingClassifier\n",
    "  p3 = ax.bar(ind, [0, 0, 0, class0_1[-1]], width, color=\"blue\", edgecolor=\"k\")\n",
    "  p4 = ax.bar(\n",
    "      ind + width, [0, 0, 0, class1_1[-1]], width, color=\"steelblue\", edgecolor=\"k\"\n",
    "  )\n",
    "\n",
    "  # plot annotations\n",
    "  plt.axvline(2.8, color=\"k\", linestyle=\"dashed\")\n",
    "  ax.set_xticks(ind + width)\n",
    "  ax.set_xticklabels(\n",
    "      [\n",
    "          \"LogisticRegression\\nweight 1\",\n",
    "          \"GaussianNB\\nweight 1\",\n",
    "          \"RandomForestClassifier\\nweight 5\",\n",
    "          \"VotingClassifier\\n(average probabilities)\",\n",
    "      ],\n",
    "      rotation=40,\n",
    "      ha=\"right\",\n",
    "  )\n",
    "  plt.ylim([0, 1])\n",
    "  plt.title(\"Class probabilities for sample 1 by different classifiers\")\n",
    "  plt.legend([p1[0], p2[0]], [\"Well Outcome: 0\", \"Well Outcome: 1\"], loc=\"upper left\")\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "r3w5v0hA4SOW"
   },
   "outputs": [],
   "source": [
    "def inp1 ():\n",
    "  drop = widgets.Dropdown(\n",
    "      options=df_column_list,\n",
    "      value=df_column_list[0],\n",
    "      description='Feature',\n",
    "      disabled=False,\n",
    "  )\n",
    "  ##Input values Field1\n",
    "  field = widgets.BoundedFloatText(\n",
    "      value=0,\n",
    "      min=0,\n",
    "      max=5,\n",
    "      #step=0.00001,\n",
    "      description='Value:',\n",
    "      disabled=False\n",
    "  )\n",
    "  slide = widgets.FloatSlider(\n",
    "      value=0,\n",
    "      min=0,\n",
    "      max=5,\n",
    "      step=0.000001,\n",
    "      description='Value:',\n",
    "      disabled=False,\n",
    "      continuous_update=False,\n",
    "      orientation='horizontal',\n",
    "      readout=True,\n",
    "      readout_format='.6f',\n",
    "      #layout=widgets.Layout(width='100%')\n",
    "  )\n",
    "  widgets.jslink((field, 'value'), (slide, 'value'))\n",
    "  def on_choose_a(d):\n",
    "    if drop.value == df_column_list[1] or drop.value == df_column_list[2] or drop.value == df_column_list[3] or  drop.value == df_column_list[4] or drop.value == df_column_list[5] or drop.value == df_column_list[6]:\n",
    "      slide.min = 0;\n",
    "      slide.max = 1;\n",
    "      slide.step = 0.000001;\n",
    "    elif drop.value == df_column_list[0]:\n",
    "      slide.min = 1;\n",
    "      slide.max = 4;\n",
    "      slide.step = 1;\n",
    "    elif drop.value == df_column_list[2]:\n",
    "      slide.min = -1;\n",
    "      slide.max = 1;\n",
    "      slide.step = 0.000001;\n",
    "    elif drop.value == df_column_list[17]:\n",
    "      slide.min = 0;\n",
    "      slide.max = 4;\n",
    "      slide.step = 1;\n",
    "    else:\n",
    "      slide.min = 0;\n",
    "      slide.max = 5;\n",
    "      slide.step = 1;\n",
    "    return slide.value\n",
    "  widgets.dlink((drop, \"value\"), (slide, \"value\"), on_choose_a)\n",
    "  return drop, field, slide;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MjlCQIRa4uX6"
   },
   "outputs": [],
   "source": [
    "\n",
    "d1, f1, s1  = inp1 ()\n",
    "d2, f2, s2  = inp1 ()\n",
    "inputa = widgets.VBox([d1, f1, s1]);\n",
    "inputb = widgets.VBox([d2, f2, s2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "pwv3ob_ytrUq"
   },
   "outputs": [],
   "source": [
    "\n",
    "column_names1 = [\"a\", \"Outcome 0: Probability (LR)\", \"Outcome 1: Probability (LR)\", \"Outcome 0: Probability (GNB)\", \"Outcome 1: Probability (GNB)\", \"Outcome 0: Probability (RF)\", \"Outcome 1: Probability (RF)\", \"Outcome 0: Probability (VC)\", \"Outcome 1: Probability (VC)\" ];\n",
    "column_names2 = [\"a\", \"b\", \"Outcome 0: Probability (LR)\", \"Outcome 1: Probability (LR)\", \"Outcome 0: Probability (GNB)\", \"Outcome 1: Probability (GNB)\", \"Outcome 0: Probability (RF)\", \"Outcome 1: Probability (RF)\", \"Outcome 0: Probability (VC)\", \"Outcome 1: Probability (VC)\" ];\n",
    "temp_for_display1 = pd.DataFrame(columns = column_names1)\n",
    "temp_for_display2 = pd.DataFrame(columns = column_names2)\n",
    "\n",
    "button0 = widgets.Button(description=\"NEW INSTANCE\", layout=Layout(width='100%', height='30px'))\n",
    "button0.style.button_color = 'gray'\n",
    "button0.style.text_color = 'black'\n",
    "\n",
    "out = widgets.Output()\n",
    "out1 = widgets.Output()\n",
    "out2 = widgets.Output()\n",
    "\n",
    "def on_button_clicked(b):\n",
    "  with out:\n",
    "    clear_output()\n",
    "  with out1:\n",
    "    clear_output()\n",
    "  with out2:\n",
    "    clear_output()\n",
    "  global temp_for_display1\n",
    "  global temp_for_display2\n",
    "  global column_names1\n",
    "  global column_names2\n",
    "  temp_for_display1 = pd.DataFrame(columns = column_names1)\n",
    "  temp_for_display2 = pd.DataFrame(columns = column_names2)\n",
    "\n",
    "\n",
    "button0.on_click(on_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "z1Go-_PzEm09"
   },
   "outputs": [],
   "source": [
    "button30 = widgets.Button(description=\"?\", button_style='warning', layout=Layout( width = \"30px\"), tooltip='Click to start a new istance \\n of feature selection.' )\n",
    "button30.style.button_color = '#b3b3ff'\n",
    "\n",
    "button3 = widgets.Button(description=\"?\", button_style='warning', layout=Layout(  width = \"30px\"), tooltip='Press to change between \\n 1 or 2 changeable features.' )\n",
    "button3.style.button_color = '#b3b3ff'\n",
    "\n",
    "button31 = widgets.Button(description=\"?\", button_style='warning', layout=Layout( width = \"30px\"), tooltip='Add feature value to input feature set and display' )\n",
    "button31.style.button_color = '#b3b3ff'\n",
    "\n",
    "button32 = widgets.Button(description=\"?\", button_style='warning', layout=Layout(  width = \"30px\"), tooltip='GENERATE PLOTS' )\n",
    "button32.style.button_color = '#b3b3ff'\n",
    "\n",
    "button33 = widgets.Button(description=\"?\", button_style='warning', layout=Layout(  width = \"30px\"), tooltip='Generate 20 Counterfactuals with \\n  the selected feature from the \\n  dropdown menu' )\n",
    "button33.style.button_color = '#b3b3ff'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "d2FqbnRJ4GnC"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Feature Selection\n",
    "select_text = widgets.HTML(value=\"<b>Select No. of Variables to modify <b>\")\n",
    "select_opt = widgets.RadioButtons(\n",
    "    options=[1, 2],\n",
    "    layout={'width': 'max-content'}, # If the items' names are long\n",
    "    disabled=False \n",
    ")\n",
    "\n",
    "\n",
    "#display(select)\n",
    "\n",
    "button = widgets.Button(description=\"Refresh!\")\n",
    "#output = widgets.Output()\n",
    "\n",
    "button_refresh = widgets.HBox([button, button3])\n",
    "select = widgets.VBox([select_text, select_opt, button_refresh])\n",
    "#display(button)\n",
    "\n",
    "input = widgets.HBox(children = [inputa])\n",
    "def on_button_clicked(b):\n",
    "    with out:\n",
    "        clear_output()\n",
    "    with out1:\n",
    "        clear_output()\n",
    "    with out2:\n",
    "        clear_output()\n",
    "    global temp_for_display1\n",
    "    global temp_for_display2\n",
    "    global column_names1\n",
    "    global column_names2\n",
    "    temp_for_display1 = pd.DataFrame(columns = column_names1)\n",
    "    temp_for_display2 = pd.DataFrame(columns = column_names2)\n",
    "    if select_opt.value ==1:\n",
    "        input.children = [inputa]\n",
    "    else:\n",
    "        input.children = [inputa, inputb]\n",
    "\n",
    "show1 = widgets.HBox([select, input])\n",
    "#display(show1)\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "CxhtTZVaof04"
   },
   "outputs": [],
   "source": [
    "#from IPython.display import display\n",
    "button1 = widgets.Button(description=\"ADD SET\")\n",
    "#button1.style.button_color = 'lightblue'\n",
    "#button1.style.text_color = ''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#display(button1)\n",
    "\n",
    "def on_button_clicked1(b):\n",
    "  if select_opt.value == 1:\n",
    "    \n",
    "    temp_for_display1.rename(columns={\"a\": d1.value }, inplace=True)\n",
    "  else:\n",
    "    temp_for_display1.rename(columns={\"a\": d1.value }, inplace=True)\n",
    "    temp_for_display2.rename(columns={\"a\": d1.value, \"b\": d2.value }, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "  temp = copy.deepcopy(Z)\n",
    "  if select_opt.value == 1:\n",
    "    temp[d1.value] = f1.value;\n",
    "  else:\n",
    "    temp[d1.value] = f1.value;\n",
    "    temp[d2.value] = f2.value;\n",
    "\n",
    "  input= pd.DataFrame(temp, index=[0,])\n",
    "  #input\n",
    "\n",
    "\n",
    "  #GET PREDICTION AND PROBABILITIES:\n",
    "\n",
    "  x = pred_val (input)\n",
    "\n",
    "  #print(list_inp)\n",
    "\n",
    "\n",
    "  if select_opt.value == 1:\n",
    "\n",
    "    list_inp = [f1.value]\n",
    "    list_inp.extend(x)\n",
    "    temp_for_display1.loc[len(temp_for_display1)] = list_inp\n",
    "    \n",
    "  else:\n",
    "    list_inp = [f1.value, f2.value]\n",
    "    list_inp.extend(x)\n",
    "    temp_for_display2.loc[len(temp_for_display2)] = list_inp\n",
    "  if select_opt.value == 1:\n",
    "    with out:\n",
    "      clear_output()\n",
    "      display(temp_for_display1)\n",
    "  else:\n",
    "    with out:\n",
    "      clear_output()\n",
    "      display(temp_for_display2)\n",
    "  #print( \"set of values added!\")\n",
    "\n",
    "button1.on_click(on_button_clicked1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "lMJAHuuKq6bX"
   },
   "outputs": [],
   "source": [
    "button2 = widgets.Button(description=\"GENERATE\", button_style='success', layout=Layout( height='100px') )\n",
    "\n",
    "\n",
    "\n",
    "def on_button_clicked2(b):\n",
    "  global temp_for_display1\n",
    "  global temp_for_display2\n",
    "  if temp_for_display1.columns[0] == 'a':\n",
    "    with out1:\n",
    "      print(\"Please add values first\")\n",
    "      return\n",
    "    with out2:\n",
    "      print(\"Please add values first\")\n",
    "      return\n",
    "  if select_opt.value == 1:\n",
    "    temp_for_display1 = temp_for_display1.sort_values(d1.value)\n",
    "    #display(temp_for_display1)\n",
    "  else:\n",
    "    temp_for_display2 = temp_for_display2.sort_values(d1.value)\n",
    "    #display(temp_for_display2)\n",
    "\n",
    "  if select_opt.value == 1:\n",
    "\n",
    "    fig1 = make_subplots(rows=2, cols=2, x_title = d1.value, y_title = \"Prediction Probability\",subplot_titles=(\"Logistic Regression\", \"Gaussian NB\", \"Random Forest Classifier\", \"Voting Classifier\"))\n",
    "\n",
    "    fig1.add_trace(go.Scatter( x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 0: Probability (LR)'].values, name = 'fefefef'), row=1, col=1)\n",
    "\n",
    "    fig1.add_trace(go.Scatter( x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 0: Probability (GNB)'].values, name = 'fefefef2'),\n",
    "              row=1, col=2)\n",
    "\n",
    "    fig1.add_trace(go.Scatter(x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 0: Probability (RF)'].values, name = 'fefefef3'),\n",
    "              row=2, col=1)\n",
    "\n",
    "    fig1.add_trace(go.Scatter(x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 0: Probability (VC)'].values, name = 'fefefef4'),\n",
    "              row=2, col=2)\n",
    "    \n",
    "    fig1.update_layout(showlegend=False)\n",
    "\n",
    "    fig2 = make_subplots(rows=2, cols=2,  x_title = d1.value, y_title = \"Prediction Probability\", subplot_titles=(\"Logistic Regression\", \"Gaussian NB\", \"Random Forest Classifier\", \"Voting Classifier\"))\n",
    "\n",
    "    fig2.add_trace(go.Scatter( x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 1: Probability (LR)'].values, name = 'fefefef'),\n",
    "              row=1, col=1)\n",
    "\n",
    "    fig2.add_trace(go.Scatter( x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 1: Probability (GNB)'].values, name = 'fefefef2'),\n",
    "              row=1, col=2)\n",
    "\n",
    "    fig2.add_trace(go.Scatter(x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 1: Probability (RF)'].values, name = 'fefefef3'),\n",
    "              row=2, col=1)\n",
    "\n",
    "    fig2.add_trace(go.Scatter(x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 1: Probability (VC)'].values, name = 'fefefef4'),\n",
    "              row=2, col=2)\n",
    "    \n",
    "    fig2.update_layout(showlegend=False)\n",
    "\n",
    "\n",
    "  if select_opt.value == 2:\n",
    "    fig3 = make_subplots(rows=2, cols=2, specs=[[{\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}],[{\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}]], subplot_titles=(\"Logistic Regression\", \"Gaussian NB\", \"Random Forest Classifier\", \"Voting Classifier\"))\n",
    "\n",
    "    fig3.add_trace(go.Scatter3d( x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values,  z = temp_for_display2['Outcome 0: Probability (LR)'].values, name = 'fefefef'),\n",
    "              row=1, col=1)\n",
    "\n",
    "    fig3.add_trace(go.Scatter3d( x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values, z = temp_for_display2['Outcome 0: Probability (GNB)'].values, name = 'fefefef2'),\n",
    "              row=1, col=2)\n",
    "\n",
    "    fig3.add_trace(go.Scatter3d(x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values, z = temp_for_display2['Outcome 0: Probability (RF)'].values, name = 'fefefef3'),\n",
    "              row=2, col=1)\n",
    "\n",
    "    fig3.add_trace(go.Scatter3d(x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values, z = temp_for_display2['Outcome 0: Probability (VC)'].values, name = 'fefefef4'),\n",
    "              row=2, col=2)\n",
    "\n",
    "    fig3.update_layout(height=900, showlegend=False)\n",
    "\n",
    "\n",
    "    fig4 = make_subplots(rows=2, cols=2, specs=[[{\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}],[{\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}]], subplot_titles=(\"Logistic Regression\", \"Gaussian NB\", \"Random Forest Classifier\", \"Voting Classifier\"))\n",
    "\n",
    "    fig4.add_trace(go.Scatter3d( x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values, z = temp_for_display2['Outcome 1: Probability (LR)'].values, name = 'fefefef'),\n",
    "              row=1, col=1)\n",
    "\n",
    "    fig4.add_trace(go.Scatter3d( x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values, z = temp_for_display2['Outcome 1: Probability (GNB)'].values, name = 'fefefef2'),\n",
    "              row=1, col=2)\n",
    "\n",
    "    fig4.add_trace(go.Scatter3d(x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values, z = temp_for_display2['Outcome 1: Probability (RF)'].values, name = 'fefefef3'),\n",
    "              row=2, col=1)\n",
    "\n",
    "    fig4.add_trace(go.Scatter3d(x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values, z = temp_for_display2['Outcome 1: Probability (VC)'].values, name = 'fefefef4'),\n",
    "              row=2, col=2)\n",
    "  \n",
    "    fig4.update_layout(height=900, showlegend=False)\n",
    "  with out:\n",
    "    clear_output()\n",
    "  with out1:\n",
    "    clear_output()\n",
    "    if select_opt.value == 1:\n",
    "      fig1.show()\n",
    "    else:\n",
    "      fig3.show()\n",
    "  with out2:\n",
    "    clear_output()\n",
    "    if select_opt.value == 1:\n",
    "      fig2.show()\n",
    "    else:\n",
    "      fig4.show()\n",
    "\n",
    "button2.on_click(on_button_clicked2)\n",
    "\n",
    "tab = widgets.Tab(children = [out1, out2])\n",
    "tab.set_title(0, 'Well Outcome: 0')\n",
    "tab.set_title(1, 'Well Outcome: 1')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "030TVbzP6iyh"
   },
   "outputs": [],
   "source": [
    "#GRENERATING COUNTERFACTUALS\n",
    "def counterfact ():\n",
    "  global Z;\n",
    "  global temp_for_display1;\n",
    "  global temp_for_display2;\n",
    "  if d1.value == df_column_list[1] or d1.value == df_column_list[2] or d1.value == df_column_list[3] or  d1.value == df_column_list[4] or d1.value == df_column_list[5] or d1.value == df_column_list[6]:\n",
    "    value1 = round(random.uniform(0,1), 6);\n",
    "  elif d1.value == df_column_list[0]:\n",
    "    value1 = random.randint(1, 4);\n",
    "  elif d1.value == df_column_list[2]:\n",
    "    value1 = round(random.uniform(-1,1), 6);\n",
    "  elif d1.value == df_column_list[17]:\n",
    "    value1 = random.randint(0, 4);\n",
    "  else:\n",
    "    value1 = random.randint(0, 5);\n",
    "  if select_opt.value == 2:\n",
    "    if d2.value == df_column_list[1] or d2.value == df_column_list[2] or d2.value == df_column_list[3] or  d2.value == df_column_list[4] or d2.value == df_column_list[5] or d2.value == df_column_list[6]:\n",
    "      value2 = round(random.uniform(0,1), 6);\n",
    "    elif d2.value == df_column_list[0]:\n",
    "      value2 = random.randint(1, 4);\n",
    "    elif d2.value == df_column_list[2]:\n",
    "      value2 = round(random.uniform(-1,1), 6);\n",
    "    elif d2.value == df_column_list[17]:\n",
    "      value2 = random.randint(0, 4);\n",
    "    else:\n",
    "      value2 = random.randint(0, 5);\n",
    "\n",
    "  if select_opt.value == 1:\n",
    "    temp_for_display1.rename(columns={\"a\": d1.value }, inplace=True)\n",
    "  else:\n",
    "    temp_for_display1.rename(columns={\"a\": d1.value }, inplace=True)\n",
    "    temp_for_display2.rename(columns={\"a\": d1.value, \"b\": d2.value }, inplace=True)\n",
    "\n",
    "  temp = copy.deepcopy(Z)\n",
    "  if select_opt.value == 1:\n",
    "    temp[d1.value] = value1;\n",
    "  else:\n",
    "    temp[d1.value] = value1;\n",
    "    temp[d2.value] = value2;\n",
    "  \n",
    "  input= pd.DataFrame(temp, index=[0,])\n",
    "\n",
    "  #GET PREDICTION AND PROBABILITIES:\n",
    "  x = pred_val (input)\n",
    "\n",
    "  if select_opt.value == 1:\n",
    "    list_inp = [value1]\n",
    "    list_inp.extend(x)\n",
    "    temp_for_display1.loc[len(temp_for_display1)] = list_inp\n",
    "  else:\n",
    "    list_inp = [value1, value2]\n",
    "    list_inp.extend(x)\n",
    "    temp_for_display2.loc[len(temp_for_display2)] = list_inp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "0F5nryDiAVhM"
   },
   "outputs": [],
   "source": [
    "button_c = widgets.Button(description=\" 20 \\n Counterfactuals\", layout=Layout( height='50px'))\n",
    "button_c.style.button_color = '#f4ad5d'\n",
    "def on_button_clickedc(b):\n",
    "  global Z;\n",
    "  global temp_for_display1;\n",
    "  global temp_for_display2;\n",
    "  for x in range(0, 20):\n",
    "    counterfact ()\n",
    "  display(temp_for_display1)\n",
    "button_c.on_click(on_button_clickedc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "lkR7HJl8QZwi"
   },
   "outputs": [],
   "source": [
    "value1 = ('Mean train accuracy for logistic regression: {:0.4f}'.format(model.score(X_train, y_train)))\n",
    "value2 = ('Mean test accuracy for logistic regression: {:0.4f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "value3 = ('Mean train accuracy for GaussianNB: {:0.4f}'.format(model3.score(X_train, y_train)))\n",
    "value4 = ('Mean test accuracy for GaussianNB: {:0.4f}'.format(model3.score(X_test, y_test)))\n",
    "\n",
    "value5 = ('Mean train accuracy for RandomForestClassifier: {:0.4f}'.format(model2.score(X_train, y_train)))\n",
    "value6 = ('Mean test accuracy for RandomForestClassifier: {:0.4f}'.format(model2.score(X_test, y_test)))\n",
    "\n",
    "value7 = ('Mean train accuracy for VotingClassifier: {:0.4f}'.format(model4.score(X_train, y_train)))\n",
    "value8 = ('Mean test accuracy for VotingClassifier: {:0.4f}'.format(model4.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "model1_text1 = widgets.HTML(value= value1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ENtRdKenq-U7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42baca46d94448838e426b95de0156a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='NEW INSTANCE', layout=Layout(height='30px', width='100%'), sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Quality Seismic</th>\n",
       "      <th>Outcome 0: Probability (LR)</th>\n",
       "      <th>Outcome 1: Probability (LR)</th>\n",
       "      <th>Outcome 0: Probability (GNB)</th>\n",
       "      <th>Outcome 1: Probability (GNB)</th>\n",
       "      <th>Outcome 0: Probability (RF)</th>\n",
       "      <th>Outcome 1: Probability (RF)</th>\n",
       "      <th>Outcome 0: Probability (VC)</th>\n",
       "      <th>Outcome 1: Probability (VC)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.587574</td>\n",
       "      <td>0.776221</td>\n",
       "      <td>0.223779</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.896387</td>\n",
       "      <td>0.103613</td>\n",
       "      <td>0.822594</td>\n",
       "      <td>0.177406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.632814</td>\n",
       "      <td>0.779327</td>\n",
       "      <td>0.220673</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.897577</td>\n",
       "      <td>0.102423</td>\n",
       "      <td>0.823888</td>\n",
       "      <td>0.176112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.673066</td>\n",
       "      <td>0.782064</td>\n",
       "      <td>0.217936</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.896966</td>\n",
       "      <td>0.103034</td>\n",
       "      <td>0.826223</td>\n",
       "      <td>0.173777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.630400</td>\n",
       "      <td>0.779162</td>\n",
       "      <td>0.220838</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.897564</td>\n",
       "      <td>0.102436</td>\n",
       "      <td>0.823855</td>\n",
       "      <td>0.176145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.407993</td>\n",
       "      <td>0.763587</td>\n",
       "      <td>0.236413</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.869254</td>\n",
       "      <td>0.130746</td>\n",
       "      <td>0.806170</td>\n",
       "      <td>0.193830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.120711</td>\n",
       "      <td>0.742372</td>\n",
       "      <td>0.257628</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.683130</td>\n",
       "      <td>0.316870</td>\n",
       "      <td>0.670194</td>\n",
       "      <td>0.329806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.373003</td>\n",
       "      <td>0.761069</td>\n",
       "      <td>0.238931</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.858588</td>\n",
       "      <td>0.141412</td>\n",
       "      <td>0.798192</td>\n",
       "      <td>0.201808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.941221</td>\n",
       "      <td>0.799673</td>\n",
       "      <td>0.200327</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.843584</td>\n",
       "      <td>0.156416</td>\n",
       "      <td>0.776323</td>\n",
       "      <td>0.223677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.841367</td>\n",
       "      <td>0.793243</td>\n",
       "      <td>0.206757</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.875640</td>\n",
       "      <td>0.124360</td>\n",
       "      <td>0.798301</td>\n",
       "      <td>0.201699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.537229</td>\n",
       "      <td>0.772728</td>\n",
       "      <td>0.227272</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.892649</td>\n",
       "      <td>0.107351</td>\n",
       "      <td>0.824186</td>\n",
       "      <td>0.175814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.591646</td>\n",
       "      <td>0.776502</td>\n",
       "      <td>0.223498</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.896576</td>\n",
       "      <td>0.103424</td>\n",
       "      <td>0.822769</td>\n",
       "      <td>0.177231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.081893</td>\n",
       "      <td>0.739412</td>\n",
       "      <td>0.260588</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.634017</td>\n",
       "      <td>0.365983</td>\n",
       "      <td>0.634690</td>\n",
       "      <td>0.365310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.915126</td>\n",
       "      <td>0.798007</td>\n",
       "      <td>0.201993</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.853827</td>\n",
       "      <td>0.146173</td>\n",
       "      <td>0.783401</td>\n",
       "      <td>0.216599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.706697</td>\n",
       "      <td>0.784332</td>\n",
       "      <td>0.215668</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.895235</td>\n",
       "      <td>0.104765</td>\n",
       "      <td>0.820549</td>\n",
       "      <td>0.179451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.020948</td>\n",
       "      <td>0.734721</td>\n",
       "      <td>0.265279</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.543431</td>\n",
       "      <td>0.456569</td>\n",
       "      <td>0.569316</td>\n",
       "      <td>0.430684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.862126</td>\n",
       "      <td>0.794592</td>\n",
       "      <td>0.205408</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.870453</td>\n",
       "      <td>0.129547</td>\n",
       "      <td>0.794789</td>\n",
       "      <td>0.205211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.394143</td>\n",
       "      <td>0.762592</td>\n",
       "      <td>0.237408</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.865296</td>\n",
       "      <td>0.134704</td>\n",
       "      <td>0.803201</td>\n",
       "      <td>0.196799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.553247</td>\n",
       "      <td>0.773844</td>\n",
       "      <td>0.226156</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.894125</td>\n",
       "      <td>0.105875</td>\n",
       "      <td>0.820638</td>\n",
       "      <td>0.179362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.318454</td>\n",
       "      <td>0.757106</td>\n",
       "      <td>0.242894</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.837050</td>\n",
       "      <td>0.162950</td>\n",
       "      <td>0.782241</td>\n",
       "      <td>0.217759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.335010</td>\n",
       "      <td>0.758314</td>\n",
       "      <td>0.241686</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.844288</td>\n",
       "      <td>0.155712</td>\n",
       "      <td>0.787584</td>\n",
       "      <td>0.212416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Data Quality Seismic  Outcome 0: Probability (LR)  \\\n",
       "0               0.587574                     0.776221   \n",
       "1               0.632814                     0.779327   \n",
       "2               0.673066                     0.782064   \n",
       "3               0.630400                     0.779162   \n",
       "4               0.407993                     0.763587   \n",
       "5               0.120711                     0.742372   \n",
       "6               0.373003                     0.761069   \n",
       "7               0.941221                     0.799673   \n",
       "8               0.841367                     0.793243   \n",
       "9               0.537229                     0.772728   \n",
       "10              0.591646                     0.776502   \n",
       "11              0.081893                     0.739412   \n",
       "12              0.915126                     0.798007   \n",
       "13              0.706697                     0.784332   \n",
       "14              0.020948                     0.734721   \n",
       "15              0.862126                     0.794592   \n",
       "16              0.394143                     0.762592   \n",
       "17              0.553247                     0.773844   \n",
       "18              0.318454                     0.757106   \n",
       "19              0.335010                     0.758314   \n",
       "\n",
       "    Outcome 1: Probability (LR)  Outcome 0: Probability (GNB)  \\\n",
       "0                      0.223779                      0.466667   \n",
       "1                      0.220673                      0.450000   \n",
       "2                      0.217936                      0.483333   \n",
       "3                      0.220838                      0.450000   \n",
       "4                      0.236413                      0.483333   \n",
       "5                      0.257628                      0.483333   \n",
       "6                      0.238931                      0.483333   \n",
       "7                      0.200327                      0.516667   \n",
       "8                      0.206757                      0.516667   \n",
       "9                      0.227272                      0.483333   \n",
       "10                     0.223498                      0.466667   \n",
       "11                     0.260588                      0.483333   \n",
       "12                     0.201993                      0.516667   \n",
       "13                     0.215668                      0.483333   \n",
       "14                     0.265279                      0.483333   \n",
       "15                     0.205408                      0.516667   \n",
       "16                     0.237408                      0.483333   \n",
       "17                     0.226156                      0.483333   \n",
       "18                     0.242894                      0.483333   \n",
       "19                     0.241686                      0.483333   \n",
       "\n",
       "    Outcome 1: Probability (GNB)  Outcome 0: Probability (RF)  \\\n",
       "0                       0.533333                     0.896387   \n",
       "1                       0.550000                     0.897577   \n",
       "2                       0.516667                     0.896966   \n",
       "3                       0.550000                     0.897564   \n",
       "4                       0.516667                     0.869254   \n",
       "5                       0.516667                     0.683130   \n",
       "6                       0.516667                     0.858588   \n",
       "7                       0.483333                     0.843584   \n",
       "8                       0.483333                     0.875640   \n",
       "9                       0.516667                     0.892649   \n",
       "10                      0.533333                     0.896576   \n",
       "11                      0.516667                     0.634017   \n",
       "12                      0.483333                     0.853827   \n",
       "13                      0.516667                     0.895235   \n",
       "14                      0.516667                     0.543431   \n",
       "15                      0.483333                     0.870453   \n",
       "16                      0.516667                     0.865296   \n",
       "17                      0.516667                     0.894125   \n",
       "18                      0.516667                     0.837050   \n",
       "19                      0.516667                     0.844288   \n",
       "\n",
       "    Outcome 1: Probability (RF)  Outcome 0: Probability (VC)  \\\n",
       "0                      0.103613                     0.822594   \n",
       "1                      0.102423                     0.823888   \n",
       "2                      0.103034                     0.826223   \n",
       "3                      0.102436                     0.823855   \n",
       "4                      0.130746                     0.806170   \n",
       "5                      0.316870                     0.670194   \n",
       "6                      0.141412                     0.798192   \n",
       "7                      0.156416                     0.776323   \n",
       "8                      0.124360                     0.798301   \n",
       "9                      0.107351                     0.824186   \n",
       "10                     0.103424                     0.822769   \n",
       "11                     0.365983                     0.634690   \n",
       "12                     0.146173                     0.783401   \n",
       "13                     0.104765                     0.820549   \n",
       "14                     0.456569                     0.569316   \n",
       "15                     0.129547                     0.794789   \n",
       "16                     0.134704                     0.803201   \n",
       "17                     0.105875                     0.820638   \n",
       "18                     0.162950                     0.782241   \n",
       "19                     0.155712                     0.787584   \n",
       "\n",
       "    Outcome 1: Probability (VC)  \n",
       "0                      0.177406  \n",
       "1                      0.176112  \n",
       "2                      0.173777  \n",
       "3                      0.176145  \n",
       "4                      0.193830  \n",
       "5                      0.329806  \n",
       "6                      0.201808  \n",
       "7                      0.223677  \n",
       "8                      0.201699  \n",
       "9                      0.175814  \n",
       "10                     0.177231  \n",
       "11                     0.365310  \n",
       "12                     0.216599  \n",
       "13                     0.179451  \n",
       "14                     0.430684  \n",
       "15                     0.205211  \n",
       "16                     0.196799  \n",
       "17                     0.179362  \n",
       "18                     0.217759  \n",
       "19                     0.212416  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button_new = widgets.HBox([button0, button30])\n",
    "button_add = widgets.HBox([button1, button31])\n",
    "val_text = widgets.HTML(value=\"<b>OR GENERATE: <b>\")\n",
    "button_coun = widgets.HBox([button_c, button33])\n",
    "button_val = widgets.VBox([button_add, val_text, button_coun])\n",
    "button_gen = widgets.HBox([button2, button32])\n",
    "show0 = widgets.HBox([button_val, button_gen])\n",
    "show2 = widgets.HBox([show1, show0])\n",
    "show3 = widgets.VBox([button_new, show2,out, tab])\n",
    "display(show3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "OXYdemo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
