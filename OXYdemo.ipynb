{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OXYdemo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#!pip install ipywidgets\n",
        "#!pip install interpret\n",
        "#!pip install dice-ml"
      ],
      "metadata": {
        "id": "HIrhUAiaqDE4"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "Ap4BbjTHRXL8"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "from __future__ import print_function\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import ipywidgets as widgets\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from interpret import show\n",
        "from interpret.blackbox import LimeTabular\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from IPython.display import display, clear_output\n",
        "# DiCE imports\n",
        "import dice_ml\n",
        "from dice_ml.utils import helpers  # helper functions\n",
        "import random\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve, confusion_matrix, auc\n",
        "def evalBinaryClassifier(model, x, y, labels=['Positives','Negatives']):\n",
        "    '''\n",
        "    Visualize the performance of  a Logistic Regression Binary Classifier.\n",
        "    \n",
        "    Displays a labelled Confusion Matrix, distributions of the predicted\n",
        "    probabilities for both classes, the ROC curve, and F1 score of a fitted\n",
        "    Binary Logistic Classifier. Author: gregcondit.com/articles/logr-charts\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    model : fitted scikit-learn model with predict_proba & predict methods\n",
        "        and classes_ attribute. Typically LogisticRegression or \n",
        "        LogisticRegressionCV\n",
        "    \n",
        "    x : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
        "        Training vector, where n_samples is the number of samples\n",
        "        in the data to be tested, and n_features is the number of features\n",
        "    \n",
        "    y : array-like, shape (n_samples,)\n",
        "        Target vector relative to x.\n",
        "    \n",
        "    labels: list, optional\n",
        "        list of text labels for the two classes, with the positive label first\n",
        "        \n",
        "    Displays\n",
        "    ----------\n",
        "    3 Subplots\n",
        "    \n",
        "    Returns\n",
        "    ----------\n",
        "    F1: float\n",
        "    '''\n",
        "    #model predicts probabilities of positive class\n",
        "    p = model.predict_proba(x)\n",
        "    if len(model.classes_)!=2:\n",
        "        raise ValueError('A binary class problem is required')\n",
        "    if model.classes_[1] == 1:\n",
        "        pos_p = p[:,1]\n",
        "    elif model.classes_[0] == 1:\n",
        "        pos_p = p[:,0]\n",
        "    \n",
        "    #FIGURE\n",
        "    plt.figure(figsize=[15,4])\n",
        "    \n",
        "    #1 -- Confusion matrix\n",
        "    cm = confusion_matrix(y,model.predict(x))\n",
        "    plt.subplot(131)\n",
        "    ax = sns.heatmap(cm, annot=True, cmap='Blues', cbar=False, \n",
        "                annot_kws={\"size\": 14}, fmt='g')\n",
        "    cmlabels = ['True Negatives', 'False Positives',\n",
        "              'False Negatives', 'True Positives']\n",
        "    for i,t in enumerate(ax.texts):\n",
        "        t.set_text(t.get_text() + \"\\n\" + cmlabels[i])\n",
        "    plt.title('Confusion Matrix', size=15)\n",
        "    plt.xlabel('Predicted Values', size=13)\n",
        "    plt.ylabel('True Values', size=13)\n",
        "      \n",
        "    #2 -- Distributions of Predicted Probabilities of both classes\n",
        "    df = pd.DataFrame({'probPos':pos_p, 'target': y})\n",
        "    plt.subplot(132)\n",
        "    plt.hist(df[df.target==1].probPos, density=True, bins=25,\n",
        "             alpha=.5, color='green',  label=labels[0])\n",
        "    plt.hist(df[df.target==0].probPos, density=True, bins=25,\n",
        "             alpha=.5, color='red', label=labels[1])\n",
        "    plt.axvline(.5, color='blue', linestyle='--', label='Boundary')\n",
        "    plt.xlim([0,1])\n",
        "    plt.title('Distributions of Predictions', size=15)\n",
        "    plt.xlabel('Positive Probability (predicted)', size=13)\n",
        "    plt.ylabel('Samples (normalized scale)', size=13)\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    \n",
        "    #3 -- ROC curve with annotated decision point\n",
        "    fp_rates, tp_rates, _ = roc_curve(y,p[:,1])\n",
        "    roc_auc = auc(fp_rates, tp_rates)\n",
        "    plt.subplot(133)\n",
        "    plt.plot(fp_rates, tp_rates, color='green',\n",
        "             lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], lw=1, linestyle='--', color='grey')\n",
        "    #plot current decision point:\n",
        "    tn, fp, fn, tp = [i for i in cm.ravel()]\n",
        "    plt.plot(fp/(fp+tn), tp/(tp+fn), 'bo', markersize=8, label='Decision Point')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', size=13)\n",
        "    plt.ylabel('True Positive Rate', size=13)\n",
        "    plt.title('ROC Curve', size=15)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.subplots_adjust(wspace=.3)\n",
        "    plt.show()\n",
        "    #Print and Return the F1 score\n",
        "    tn, fp, fn, tp = [i for i in cm.ravel()]\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    F1 = 2*(precision * recall) / (precision + recall)\n",
        "    printout = (\n",
        "        f'Precision: {round(precision,2)} | '\n",
        "        f'Recall: {round(recall,2)} | '\n",
        "        f'F1 Score: {round(F1,2)} | '\n",
        "    )\n",
        "    print(printout)\n",
        "    return F1"
      ],
      "metadata": {
        "id": "HUL8Ow6hfyGM"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load and read data\n",
        "f = open('/content/oxy_data.csv')\n",
        "df = pd.read_csv(f, header=0, index_col=False, engine='c', encoding='UTF-8')\n",
        "\n",
        "# delete Nan values from the feature dataframe\n",
        "df_column_list = df.columns.tolist()  # extract all column names into a list\n",
        "for column_name in df_column_list:\n",
        "    df = df.drop(df.index[df[column_name] == 'NA()'])\n",
        "\n",
        "# delete Nan values from the feature dataframe\n",
        "df_column_list = df.columns.tolist()  # extract all column names into a list\n",
        "for column_name in df_column_list:\n",
        "    df = df.drop(df.index[df[column_name] == '2P'])\n",
        "\n",
        "#drop all rows with null values\n",
        "\n",
        "df.dropna(inplace = True)\n",
        "\n",
        "#rearranging coloumns to bring outcome to front\n",
        "df_column_list = df.columns.tolist() \n",
        "temp = df_column_list[0]\n",
        "df_column_list[0] = df_column_list[1];\n",
        "df_column_list[1] = temp\n",
        "df_column_list\n",
        "df=df.reindex(columns=df_column_list)\n",
        "df.head()\n",
        "\n",
        "#SPLIT SETS\n",
        "X, y = df[df.columns[1:34]], df[df.columns[0]] \n",
        "X.head()\n",
        "\n",
        "# set appropriate datatypes\n",
        "X, y = X.astype(float), y.astype(int)\n",
        "\n",
        "\n",
        "# train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
        "\n"
      ],
      "metadata": {
        "id": "4zDDadYkRugr"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# fit a linear logistic regression model\n",
        "model = LogisticRegression(max_iter = 300).fit(X_train, y_train)\n",
        "\n",
        "# print accuracies on train and test sets\n",
        "#print('Mean train accuracy for logistic regression: {:0.4f}'.format(model.score(X_train, y_train)))\n",
        "#print('Mean test accuracy for logistic regression: {:0.4f}'.format(model.score(X_test, y_test)))\n",
        "\n",
        "\n",
        "with open('model.pkl','wb') as f:\n",
        "    pickle.dump(model,f)"
      ],
      "metadata": {
        "id": "0P_pI2rlWkRw"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H = X_test.head(1).reset_index(drop = \"True\")\n",
        "Z = H.to_dict('records')[0] #singular value to dictionary for updates\n"
      ],
      "metadata": {
        "id": "SKZNOeI5dJHs"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# fit a RandomForestClassifier\n",
        "\n",
        "model2 = RandomForestClassifier(n_estimators=60).fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# print accuracies on train and test sets\n",
        "#print('Mean train accuracy for RandomForestClassifier: {:0.4f}'.format(model2.score(X_train, y_train)))\n",
        "#print('Mean test accuracy for RandomForestClassifier: {:0.4f}'.format(model2.score(X_test, y_test)))\n",
        "\n"
      ],
      "metadata": {
        "id": "cuBtsrngirC8"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#fit a GaussianNB\n",
        "\n",
        "model3 = GaussianNB().fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# print accuracies on train and test sets\n",
        "#print('Mean train accuracy for GaussianNB: {:0.4f}'.format(model3.score(X_train, y_train)))\n",
        "#print('Mean test accuracy for GaussianNB: {:0.4f}'.format(model3.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "23tEfglJlkyM"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "#fit a VotingClassifier\n",
        "\n",
        "model4 = VotingClassifier(\n",
        "    estimators=[(\"lr\", model), (\"rf\", model2), (\"gnb\", model3)],\n",
        "    voting=\"soft\",\n",
        "    weights=[1, 1, 5],\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "# print accuracies on train and test sets\n",
        "#print('Mean train accuracy for VotingClassifier: {:0.4f}'.format(model4.score(X_train, y_train)))\n",
        "#print('Mean test accuracy for VotingClassifier: {:0.4f}'.format(model4.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "f1yus5O8l14K"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#F1 = evalBinaryClassifier(model,X_test,y_test)"
      ],
      "metadata": {
        "id": "ml2ybUazfyYG"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#F2 = evalBinaryClassifier(model2,X_test,y_test)"
      ],
      "metadata": {
        "id": "nbOjg-9Zi28m"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#F3 = evalBinaryClassifier(model3,X_test,y_test)"
      ],
      "metadata": {
        "id": "Fr-xtqhkloHO"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find max and min values\n",
        "\n",
        "df_column_list = X.columns.tolist() \n",
        "df_column_list[1]\n",
        "l = (len(df_column_list))"
      ],
      "metadata": {
        "id": "McM3kIKnsMtr"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_val (A):\n",
        "\n",
        "  #predict output for all classifiers\n",
        "  prediction = [c.predict(A) for c in (model, model2, model3, model4)]\n",
        "  #print(\"Sample input: \") \n",
        "  #display(A.head(1))\n",
        "  #get prediction for only first sample\n",
        "  result = [pr[0] for pr in prediction]\n",
        "\n",
        "\n",
        "  # predict class probabilities for all classifiers\n",
        "  probas = [c.predict_proba(A) for c in (model, model2, model3, model4)]\n",
        "\n",
        "  # get class probabilities for the first sample in the dataset\n",
        "  class0_1 = [pr[0, 0] for pr in probas]\n",
        "  class1_1 = [pr[0, 1] for pr in probas]\n",
        "\n",
        "  #printing values\n",
        "  #prediction:\n",
        "\n",
        "  #print(\"The predicted class by LogisticRegression is: \" + str(result[0]) + \" with positive class probability being \" +str(max(class0_1[0],class1_1[0])))\n",
        "  #print(\"The predicted class by GaussianNB is: \" + str(result[1]) + \" with positive class probability being \" +str(max(class0_1[1],class1_1[1])))\n",
        "  #print(\"The predicted class by RandomForestClassifier is: \" + str(result[2]) + \" with positive class probability being \" +str(max(class0_1[2],class1_1[2])))\n",
        "  #print(\"The predicted class by VotingClassifier is: \" + str(result[3]) + \" with positive class probability being \" +str(max(class0_1[3],class1_1[3])))\n",
        "  return [class0_1[0],class1_1[0],class0_1[1],class1_1[1],class0_1[2],class1_1[2],class0_1[3],class1_1[3]]\n"
      ],
      "metadata": {
        "id": "hONfttBjUMXW"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred (A):\n",
        "\n",
        "  #predict output for all classifiers\n",
        "  prediction = [c.predict(X_test) for c in (model, model2, model3, model4)]\n",
        "  print(\"Sample input: \") \n",
        "  display(X_test.head(1))\n",
        "  #get prediction for only first sample\n",
        "  result = [pr[0] for pr in prediction]\n",
        "\n",
        "\n",
        "  # predict class probabilities for all classifiers\n",
        "  probas = [c.predict_proba(X_test) for c in (model, model2, model3, model4)]\n",
        "\n",
        "  # get class probabilities for the first sample in the dataset\n",
        "  class0_1 = [pr[0, 0] for pr in probas]\n",
        "  class1_1 = [pr[0, 1] for pr in probas]\n",
        "\n",
        "  #printing values\n",
        "  #prediction:\n",
        "\n",
        "  print(\"The predicted class by LogisticRegression is: \" + str(result[0]) + \" with positive class probability being \" +str(max(class0_1[0],class1_1[0])))\n",
        "  print(\"The predicted class by GaussianNB is: \" + str(result[1]) + \" with positive class probability being \" +str(max(class0_1[1],class1_1[1])))\n",
        "  print(\"The predicted class by RandomForestClassifier is: \" + str(result[2]) + \" with positive class probability being \" +str(max(class0_1[2],class1_1[2])))\n",
        "  print(\"The predicted class by VotingClassifier is: \" + str(result[3]) + \" with positive class probability being \" +str(max(class0_1[3],class1_1[3])))\n",
        "\n",
        "  # plotting\n",
        "\n",
        "  N = 4  # number of groups\n",
        "  ind = np.arange(N)  # group positions\n",
        "  width = 0.35  # bar width\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "\n",
        "  # bars for classifier 1-3\n",
        "\n",
        "  p1 = ax.bar(ind, np.hstack(([class0_1[:-1], [0]])), width, color=\"green\", edgecolor=\"k\")\n",
        "  p2 = ax.bar(\n",
        "      ind + width,\n",
        "      np.hstack(([class1_1[:-1], [0]])),\n",
        "      width,\n",
        "      color=\"lightgreen\",\n",
        "      edgecolor=\"k\",\n",
        "  )\n",
        "\n",
        "  # bars for VotingClassifier\n",
        "  p3 = ax.bar(ind, [0, 0, 0, class0_1[-1]], width, color=\"blue\", edgecolor=\"k\")\n",
        "  p4 = ax.bar(\n",
        "      ind + width, [0, 0, 0, class1_1[-1]], width, color=\"steelblue\", edgecolor=\"k\"\n",
        "  )\n",
        "\n",
        "  # plot annotations\n",
        "  plt.axvline(2.8, color=\"k\", linestyle=\"dashed\")\n",
        "  ax.set_xticks(ind + width)\n",
        "  ax.set_xticklabels(\n",
        "      [\n",
        "          \"LogisticRegression\\nweight 1\",\n",
        "          \"GaussianNB\\nweight 1\",\n",
        "          \"RandomForestClassifier\\nweight 5\",\n",
        "          \"VotingClassifier\\n(average probabilities)\",\n",
        "      ],\n",
        "      rotation=40,\n",
        "      ha=\"right\",\n",
        "  )\n",
        "  plt.ylim([0, 1])\n",
        "  plt.title(\"Class probabilities for sample 1 by different classifiers\")\n",
        "  plt.legend([p1[0], p2[0]], [\"Well Outcome: 0\", \"Well Outcome: 1\"], loc=\"upper left\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "BkYyqvm5TSne"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inp1 ():\n",
        "  drop = widgets.Dropdown(\n",
        "      options=df_column_list,\n",
        "      value=df_column_list[0],\n",
        "      description='Feature',\n",
        "      disabled=False,\n",
        "  )\n",
        "  ##Input values Field1\n",
        "  field = widgets.BoundedFloatText(\n",
        "      value=0,\n",
        "      min=0,\n",
        "      max=5,\n",
        "      #step=0.00001,\n",
        "      description='Value:',\n",
        "      disabled=False\n",
        "  )\n",
        "  slide = widgets.FloatSlider(\n",
        "      value=0,\n",
        "      min=0,\n",
        "      max=5,\n",
        "      step=0.000001,\n",
        "      description='Value:',\n",
        "      disabled=False,\n",
        "      continuous_update=False,\n",
        "      orientation='horizontal',\n",
        "      readout=True,\n",
        "      readout_format='.6f',\n",
        "      #layout=widgets.Layout(width='100%')\n",
        "  )\n",
        "  widgets.jslink((field, 'value'), (slide, 'value'))\n",
        "  def on_choose_a(d):\n",
        "    if drop.value == df_column_list[1] or drop.value == df_column_list[2] or drop.value == df_column_list[3] or  drop.value == df_column_list[4] or drop.value == df_column_list[5] or drop.value == df_column_list[6]:\n",
        "      slide.min = 0;\n",
        "      slide.max = 1;\n",
        "      slide.step = 0.000001;\n",
        "    elif drop.value == df_column_list[0]:\n",
        "      slide.min = 1;\n",
        "      slide.max = 4;\n",
        "      slide.step = 1;\n",
        "    elif drop.value == df_column_list[2]:\n",
        "      slide.min = -1;\n",
        "      slide.max = 1;\n",
        "      slide.step = 0.000001;\n",
        "    elif drop.value == df_column_list[17]:\n",
        "      slide.min = 0;\n",
        "      slide.max = 4;\n",
        "      slide.step = 1;\n",
        "    else:\n",
        "      slide.min = 0;\n",
        "      slide.max = 5;\n",
        "      slide.step = 1;\n",
        "    return slide.value\n",
        "  widgets.dlink((drop, \"value\"), (slide, \"value\"), on_choose_a)\n",
        "  return drop, field, slide;"
      ],
      "metadata": {
        "id": "r3w5v0hA4SOW"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "d1, f1, s1  = inp1 ()\n",
        "d2, f2, s2  = inp1 ()\n",
        "inputa = widgets.VBox([d1, f1, s1]);\n",
        "inputb = widgets.VBox([d2, f2, s2]);"
      ],
      "metadata": {
        "id": "MjlCQIRa4uX6"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "column_names1 = [\"a\", \"Outcome 0: Probability (LR)\", \"Outcome 1: Probability (LR)\", \"Outcome 0: Probability (GNB)\", \"Outcome 1: Probability (GNB)\", \"Outcome 0: Probability (RF)\", \"Outcome 1: Probability (RF)\", \"Outcome 0: Probability (VC)\", \"Outcome 1: Probability (VC)\" ];\n",
        "column_names2 = [\"a\", \"b\", \"Outcome 0: Probability (LR)\", \"Outcome 1: Probability (LR)\", \"Outcome 0: Probability (GNB)\", \"Outcome 1: Probability (GNB)\", \"Outcome 0: Probability (RF)\", \"Outcome 1: Probability (RF)\", \"Outcome 0: Probability (VC)\", \"Outcome 1: Probability (VC)\" ];\n",
        "temp_for_display1 = pd.DataFrame(columns = column_names1)\n",
        "temp_for_display2 = pd.DataFrame(columns = column_names2)\n",
        "\n",
        "button0 = widgets.Button(description=\"NEW INSTANCE\", layout=Layout(width='100%', height='30px'))\n",
        "button0.style.button_color = 'gray'\n",
        "button0.style.text_color = 'black'\n",
        "\n",
        "out = widgets.Output()\n",
        "out1 = widgets.Output()\n",
        "out2 = widgets.Output()\n",
        "\n",
        "def on_button_clicked(b):\n",
        "  with out:\n",
        "    clear_output()\n",
        "  with out1:\n",
        "    clear_output()\n",
        "  with out2:\n",
        "    clear_output()\n",
        "  global temp_for_display1\n",
        "  global temp_for_display2\n",
        "  global column_names1\n",
        "  global column_names2\n",
        "  temp_for_display1 = pd.DataFrame(columns = column_names1)\n",
        "  temp_for_display2 = pd.DataFrame(columns = column_names2)\n",
        "\n",
        "\n",
        "button0.on_click(on_button_clicked)\n"
      ],
      "metadata": {
        "id": "pwv3ob_ytrUq"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "button30 = widgets.Button(description=\"?\", button_style='warning', layout=Layout( width = \"30px\"), tooltip='Click to start a new istance \\n of feature selection.' )\n",
        "button30.style.button_color = '#b3b3ff'\n",
        "\n",
        "button3 = widgets.Button(description=\"?\", button_style='warning', layout=Layout(  width = \"30px\"), tooltip='Press to change between \\n 1 or 2 changeable features.' )\n",
        "button3.style.button_color = '#b3b3ff'\n",
        "\n",
        "button31 = widgets.Button(description=\"?\", button_style='warning', layout=Layout( width = \"30px\"), tooltip='Add feature value to input feature set and display' )\n",
        "button31.style.button_color = '#b3b3ff'\n",
        "\n",
        "button32 = widgets.Button(description=\"?\", button_style='warning', layout=Layout(  width = \"30px\"), tooltip='GENERATE PLOTS' )\n",
        "button32.style.button_color = '#b3b3ff'\n",
        "\n",
        "button33 = widgets.Button(description=\"?\", button_style='warning', layout=Layout(  width = \"30px\"), tooltip='Generate 20 Counterfactuals with \\n  the selected feature from the \\n  dropdown menu' )\n",
        "button33.style.button_color = '#b3b3ff'\n"
      ],
      "metadata": {
        "id": "z1Go-_PzEm09"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "## Feature Selection\n",
        "select_text = widgets.HTML(value=\"<b>Select No. of Variables to modify <b>\")\n",
        "select_opt = widgets.RadioButtons(\n",
        "    options=[1, 2],\n",
        "    layout={'width': 'max-content'}, # If the items' names are long\n",
        "    disabled=False \n",
        ")\n",
        "\n",
        "\n",
        "#display(select)\n",
        "\n",
        "button = widgets.Button(description=\"Refresh!\")\n",
        "#output = widgets.Output()\n",
        "\n",
        "button_refresh = widgets.HBox([button, button3])\n",
        "select = widgets.VBox([select_text, select_opt, button_refresh])\n",
        "#display(button)\n",
        "\n",
        "input = widgets.HBox(children = [inputa])\n",
        "def on_button_clicked(b):\n",
        "  if select_opt.value ==1:\n",
        "    input.children = [inputa]\n",
        "  else:\n",
        "    input.children = [inputa, inputb]\n",
        "\n",
        "show1 = widgets.HBox([select, input])\n",
        "#display(show1)\n",
        "\n",
        "button.on_click(on_button_clicked)\n",
        "\n"
      ],
      "metadata": {
        "id": "d2FqbnRJ4GnC"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from IPython.display import display\n",
        "button1 = widgets.Button(description=\"ADD SET\")\n",
        "#button1.style.button_color = 'lightblue'\n",
        "#button1.style.text_color = ''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#display(button1)\n",
        "\n",
        "def on_button_clicked1(b):\n",
        "  if select_opt.value == 1:\n",
        "    \n",
        "    temp_for_display1.rename(columns={\"a\": d1.value }, inplace=True)\n",
        "  else:\n",
        "    temp_for_display1.rename(columns={\"a\": d1.value }, inplace=True)\n",
        "    temp_for_display2.rename(columns={\"a\": d1.value, \"b\": d2.value }, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "  temp = copy.deepcopy(Z)\n",
        "  if select_opt.value == 1:\n",
        "    temp[d1.value] = f1.value;\n",
        "  else:\n",
        "    temp[d1.value] = f1.value;\n",
        "    temp[d2.value] = f2.value;\n",
        "\n",
        "  input= pd.DataFrame(temp, index=[0,])\n",
        "  #input\n",
        "\n",
        "\n",
        "  #GET PREDICTION AND PROBABILITIES:\n",
        "\n",
        "  x = pred_val (input)\n",
        "\n",
        "  #print(list_inp)\n",
        "\n",
        "\n",
        "  if select_opt.value == 1:\n",
        "\n",
        "    list_inp = [f1.value]\n",
        "    list_inp.extend(x)\n",
        "    temp_for_display1.loc[len(temp_for_display1)] = list_inp\n",
        "    \n",
        "  else:\n",
        "    list_inp = [f1.value, f2.value]\n",
        "    list_inp.extend(x)\n",
        "    temp_for_display2.loc[len(temp_for_display2)] = list_inp\n",
        "  if select_opt.value == 1:\n",
        "    with out:\n",
        "      clear_output()\n",
        "      display(temp_for_display1)\n",
        "  else:\n",
        "    with out:\n",
        "      clear_output()\n",
        "      display(temp_for_display2)\n",
        "  #print( \"set of values added!\")\n",
        "\n",
        "button1.on_click(on_button_clicked1)"
      ],
      "metadata": {
        "id": "CxhtTZVaof04"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "button2 = widgets.Button(description=\"GENERATE\", button_style='success', layout=Layout( height='100px') )\n",
        "\n",
        "\n",
        "\n",
        "def on_button_clicked2(b):\n",
        "  global temp_for_display1\n",
        "  global temp_for_display2\n",
        "  if temp_for_display1.columns[0] == 'a':\n",
        "    with out1:\n",
        "      print(\"Please add values first\")\n",
        "      return\n",
        "    with out2:\n",
        "      print(\"Please add values first\")\n",
        "      return\n",
        "  if select_opt.value == 1:\n",
        "    temp_for_display1 = temp_for_display1.sort_values(d1.value)\n",
        "    #display(temp_for_display1)\n",
        "  else:\n",
        "    temp_for_display2 = temp_for_display2.sort_values(d1.value)\n",
        "    #display(temp_for_display2)\n",
        "\n",
        "  if select_opt.value == 1:\n",
        "\n",
        "    fig1 = make_subplots(rows=2, cols=2, x_title = d1.value, y_title = \"Prediction Probability\",subplot_titles=(\"Logistic Regression\", \"Gaussian NB\", \"Random Forest Classifier\", \"Voting Classifier\"))\n",
        "\n",
        "    fig1.add_trace(go.Scatter( x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 0: Probability (LR)'].values, name = 'fefefef'), row=1, col=1)\n",
        "\n",
        "    fig1.add_trace(go.Scatter( x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 0: Probability (GNB)'].values, name = 'fefefef2'),\n",
        "              row=1, col=2)\n",
        "\n",
        "    fig1.add_trace(go.Scatter(x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 0: Probability (RF)'].values, name = 'fefefef3'),\n",
        "              row=2, col=1)\n",
        "\n",
        "    fig1.add_trace(go.Scatter(x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 0: Probability (VC)'].values, name = 'fefefef4'),\n",
        "              row=2, col=2)\n",
        "    \n",
        "    fig1.update_layout(showlegend=False)\n",
        "\n",
        "    fig2 = make_subplots(rows=2, cols=2,  x_title = d1.value, y_title = \"Prediction Probability\", subplot_titles=(\"Logistic Regression\", \"Gaussian NB\", \"Random Forest Classifier\", \"Voting Classifier\"))\n",
        "\n",
        "    fig2.add_trace(go.Scatter( x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 1: Probability (LR)'].values, name = 'fefefef'),\n",
        "              row=1, col=1)\n",
        "\n",
        "    fig2.add_trace(go.Scatter( x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 1: Probability (GNB)'].values, name = 'fefefef2'),\n",
        "              row=1, col=2)\n",
        "\n",
        "    fig2.add_trace(go.Scatter(x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 1: Probability (RF)'].values, name = 'fefefef3'),\n",
        "              row=2, col=1)\n",
        "\n",
        "    fig2.add_trace(go.Scatter(x = temp_for_display1[d1.value].values , y = temp_for_display1['Outcome 1: Probability (VC)'].values, name = 'fefefef4'),\n",
        "              row=2, col=2)\n",
        "    \n",
        "    fig2.update_layout(showlegend=False)\n",
        "\n",
        "\n",
        "  if select_opt.value == 2:\n",
        "    fig3 = make_subplots(rows=2, cols=2, specs=[[{\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}],[{\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}]], subplot_titles=(\"Logistic Regression\", \"Gaussian NB\", \"Random Forest Classifier\", \"Voting Classifier\"))\n",
        "\n",
        "    fig3.add_trace(go.Scatter3d( x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values,  z = temp_for_display2['Outcome 0: Probability (LR)'].values, name = 'fefefef'),\n",
        "              row=1, col=1)\n",
        "\n",
        "    fig3.add_trace(go.Scatter3d( x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values, z = temp_for_display2['Outcome 0: Probability (GNB)'].values, name = 'fefefef2'),\n",
        "              row=1, col=2)\n",
        "\n",
        "    fig3.add_trace(go.Scatter3d(x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values, z = temp_for_display2['Outcome 0: Probability (RF)'].values, name = 'fefefef3'),\n",
        "              row=2, col=1)\n",
        "\n",
        "    fig3.add_trace(go.Scatter3d(x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values, z = temp_for_display2['Outcome 0: Probability (VC)'].values, name = 'fefefef4'),\n",
        "              row=2, col=2)\n",
        "\n",
        "    fig3.update_layout(height=900, showlegend=False)\n",
        "\n",
        "\n",
        "    fig4 = make_subplots(rows=2, cols=2, specs=[[{\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}],[{\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}]], subplot_titles=(\"Logistic Regression\", \"Gaussian NB\", \"Random Forest Classifier\", \"Voting Classifier\"))\n",
        "\n",
        "    fig4.add_trace(go.Scatter3d( x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values, z = temp_for_display2['Outcome 1: Probability (LR)'].values, name = 'fefefef'),\n",
        "              row=1, col=1)\n",
        "\n",
        "    fig4.add_trace(go.Scatter3d( x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values, z = temp_for_display2['Outcome 1: Probability (GNB)'].values, name = 'fefefef2'),\n",
        "              row=1, col=2)\n",
        "\n",
        "    fig4.add_trace(go.Scatter3d(x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values, z = temp_for_display2['Outcome 1: Probability (RF)'].values, name = 'fefefef3'),\n",
        "              row=2, col=1)\n",
        "\n",
        "    fig4.add_trace(go.Scatter3d(x = temp_for_display2[d1.value].values , y = temp_for_display2[d2.value].values, z = temp_for_display2['Outcome 1: Probability (VC)'].values, name = 'fefefef4'),\n",
        "              row=2, col=2)\n",
        "  \n",
        "    fig4.update_layout(height=900, showlegend=False)\n",
        "  with out:\n",
        "    clear_output()\n",
        "  with out1:\n",
        "    clear_output()\n",
        "    if select_opt.value == 1:\n",
        "      fig1.show()\n",
        "    else:\n",
        "      fig3.show()\n",
        "  with out2:\n",
        "    clear_output()\n",
        "    if select_opt.value == 1:\n",
        "      fig2.show()\n",
        "    else:\n",
        "      fig4.show()\n",
        "\n",
        "button2.on_click(on_button_clicked2)\n",
        "\n",
        "tab = widgets.Tab(children = [out1, out2])\n",
        "tab.set_title(0, 'Well Outcome: 0')\n",
        "tab.set_title(1, 'Well Outcome: 1')\n",
        "#"
      ],
      "metadata": {
        "id": "lMJAHuuKq6bX"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GRENERATING COUNTERFACTUALS\n",
        "def counterfact ():\n",
        "  global Z;\n",
        "  global temp_for_display1;\n",
        "  global temp_for_display2;\n",
        "  if d1.value == df_column_list[1] or d1.value == df_column_list[2] or d1.value == df_column_list[3] or  d1.value == df_column_list[4] or d1.value == df_column_list[5] or d1.value == df_column_list[6]:\n",
        "    value1 = round(random.uniform(0,1), 6);\n",
        "  elif d1.value == df_column_list[0]:\n",
        "    value1 = random.randint(1, 4);\n",
        "  elif d1.value == df_column_list[2]:\n",
        "    value1 = round(random.uniform(-1,1), 6);\n",
        "  elif d1.value == df_column_list[17]:\n",
        "    value1 = random.randint(0, 4);\n",
        "  else:\n",
        "    value1 = random.randint(0, 5);\n",
        "  if select_opt.value == 2:\n",
        "    if d2.value == df_column_list[1] or d2.value == df_column_list[2] or d2.value == df_column_list[3] or  d2.value == df_column_list[4] or d2.value == df_column_list[5] or d2.value == df_column_list[6]:\n",
        "      value2 = round(random.uniform(0,1), 6);\n",
        "    elif d2.value == df_column_list[0]:\n",
        "      value2 = random.randint(1, 4);\n",
        "    elif d2.value == df_column_list[2]:\n",
        "      value2 = round(random.uniform(-1,1), 6);\n",
        "    elif d2.value == df_column_list[17]:\n",
        "      value2 = random.randint(0, 4);\n",
        "    else:\n",
        "      value2 = random.randint(0, 5);\n",
        "\n",
        "  if select_opt.value == 1:\n",
        "    temp_for_display1.rename(columns={\"a\": d1.value }, inplace=True)\n",
        "  else:\n",
        "    temp_for_display1.rename(columns={\"a\": d1.value }, inplace=True)\n",
        "    temp_for_display2.rename(columns={\"a\": d1.value, \"b\": d2.value }, inplace=True)\n",
        "\n",
        "  temp = copy.deepcopy(Z)\n",
        "  if select_opt.value == 1:\n",
        "    temp[d1.value] = value1;\n",
        "  else:\n",
        "    temp[d1.value] = value1;\n",
        "    temp[d2.value] = value2;\n",
        "  \n",
        "  input= pd.DataFrame(temp, index=[0,])\n",
        "\n",
        "  #GET PREDICTION AND PROBABILITIES:\n",
        "  x = pred_val (input)\n",
        "\n",
        "  if select_opt.value == 1:\n",
        "    list_inp = [value1]\n",
        "    list_inp.extend(x)\n",
        "    temp_for_display1.loc[len(temp_for_display1)] = list_inp\n",
        "  else:\n",
        "    list_inp = [value1, value2]\n",
        "    list_inp.extend(x)\n",
        "    temp_for_display2.loc[len(temp_for_display2)] = list_inp\n"
      ],
      "metadata": {
        "id": "030TVbzP6iyh"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "button_c = widgets.Button(description=\" 20 \\n Counterfactuals\", layout=Layout( height='50px'))\n",
        "button_c.style.button_color = '#f4ad5d'\n",
        "def on_button_clickedc(b):\n",
        "  global Z;\n",
        "  global temp_for_display1;\n",
        "  global temp_for_display2;\n",
        "  for x in range(0, 20):\n",
        "    counterfact ()\n",
        "  #display(temp_for_display1)\n",
        "button_c.on_click(on_button_clickedc)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0F5nryDiAVhM"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value1 = ('Mean train accuracy for logistic regression: {:0.4f}'.format(model.score(X_train, y_train)))\n",
        "value2 = ('Mean test accuracy for logistic regression: {:0.4f}'.format(model.score(X_test, y_test)))\n",
        "\n",
        "value3 = ('Mean train accuracy for GaussianNB: {:0.4f}'.format(model3.score(X_train, y_train)))\n",
        "value4 = ('Mean test accuracy for GaussianNB: {:0.4f}'.format(model3.score(X_test, y_test)))\n",
        "\n",
        "value5 = ('Mean train accuracy for RandomForestClassifier: {:0.4f}'.format(model2.score(X_train, y_train)))\n",
        "value6 = ('Mean test accuracy for RandomForestClassifier: {:0.4f}'.format(model2.score(X_test, y_test)))\n",
        "\n",
        "value7 = ('Mean train accuracy for VotingClassifier: {:0.4f}'.format(model4.score(X_train, y_train)))\n",
        "value8 = ('Mean test accuracy for VotingClassifier: {:0.4f}'.format(model4.score(X_test, y_test)))\n",
        "\n",
        "\n",
        "model1_text1 = widgets.HTML(value= value1)\n"
      ],
      "metadata": {
        "id": "lkR7HJl8QZwi"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "button_new = widgets.HBox([button0, button30])\n",
        "button_add = widgets.HBox([button1, button31])\n",
        "val_text = widgets.HTML(value=\"<b>OR GENERATE: <b>\")\n",
        "button_coun = widgets.HBox([button_c, button33])\n",
        "button_val = widgets.VBox([button_add, val_text, button_coun])\n",
        "button_gen = widgets.HBox([button2, button32])\n",
        "show0 = widgets.HBox([button_val, button_gen])\n",
        "show2 = widgets.HBox([show1, show0])\n",
        "show3 = widgets.VBox([button_new, show2,out, tab])\n",
        "display(show3)"
      ],
      "metadata": {
        "id": "ENtRdKenq-U7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}